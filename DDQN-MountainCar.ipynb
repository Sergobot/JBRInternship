{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd9800435b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 11\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def construct_nn(sizes: list, output=nn.Identity):\n",
    "    layers = []\n",
    "    for i in range(len(sizes) - 1):\n",
    "        act = nn.ReLU if i < len(sizes) - 2 else output\n",
    "        layers += [nn.Linear(sizes[i], sizes[i+1]), act()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, sizes):\n",
    "        super().__init__()\n",
    "        self.policy = construct_nn([obs_dim] + sizes + [act_dim])\n",
    "        self.target = construct_nn([obs_dim] + sizes + [act_dim])\n",
    "        self.target.load_state_dict(self.policy.state_dict())\n",
    "        self.target.eval()\n",
    "    \n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            return self.policy(obs).max(0)[1].view(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, act_dim, size):\n",
    "        self.obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.act_buf = np.zeros((size, act_dim), dtype=np.float32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros((size, obs_dim), dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "\n",
    "        self.ptr, self.size, self.limit = 0, 0, size\n",
    "    \n",
    "    def put(self, obs, act, rew, next_obs, done):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.limit\n",
    "        self.size = min(self.size + 1, self.limit)\n",
    "    \n",
    "    def sample_batch(self, batch_size):\n",
    "        idx = np.random.randint(0, self.size, size=batch_size)\n",
    "        return {\n",
    "            'obs': torch.as_tensor(self.obs_buf[idx], dtype=torch.float32),\n",
    "            'act': torch.as_tensor(self.act_buf[idx], dtype=torch.float32),\n",
    "            'rew': torch.as_tensor(self.rew_buf[idx], dtype=torch.float32),\n",
    "            'next_obs': torch.as_tensor(self.next_obs_buf[idx], dtype=torch.float32),\n",
    "            'done': torch.as_tensor(self.done_buf[idx], dtype=torch.float32)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "GAMMA = 0.99\n",
    "TARGET_UPDATE = 10\n",
    "TARGET_UPDATE_AFTER = 30\n",
    "NETWORK_SIZES = [24, 48]\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_LEN = 200\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "EPOCHS = 10\n",
    "EPISODES_PER_EPOCH = 50\n",
    "\n",
    "start = 0\n",
    "total_steps = 0\n",
    "\n",
    "Logger = dict(\n",
    "    loss=[],\n",
    "    ret=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(SEED)\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(obs_dim, 1, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ddqn = DDQN(obs_dim, act_dim, NETWORK_SIZES).to(dev)\n",
    "ddqn_optimizer = optim.Adam(ddqn.policy.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(q, q_exp):\n",
    "    return F.mse_loss(q, q_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize():\n",
    "    if len(buffer) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    batch = buffer.sample_batch(BATCH_SIZE)\n",
    "    obs, act, rew, next_obs, done = \\\n",
    "            batch['obs'], batch['act'], batch['rew'], batch['next_obs'], batch['done']\n",
    "    \n",
    "    q = ddqn.policy(obs).gather(1, torch.as_tensor(act, dtype=torch.long))\n",
    "    q_best_by_policy = ddqn.policy(obs).max(1)[1].detach()\n",
    "    q_next = ddqn.target(obs).gather(1, q_best_by_policy.view(-1, 1)).squeeze().detach()\n",
    "    q_exp = (q_next * GAMMA) + rew\n",
    "\n",
    "    ddqn_optimizer.zero_grad()\n",
    "    loss = compute_loss(q, q_exp.unsqueeze(1))\n",
    "    Logger['loss'].append(loss.item())\n",
    "    loss.backward()\n",
    "    ddqn_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(obs):\n",
    "    eps = np.random.random(1)[0]\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * total_steps / EPS_DECAY)\n",
    "    \n",
    "    if eps > eps_threshold:\n",
    "        return ddqn.act(obs).item()\n",
    "    else:\n",
    "        return np.random.choice(act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Epoch has started!\n",
      "[0] Epoch has completed: loss=3361.267687718617 min_loss=0.0028642904944717884 avg_ret=-200.0\n",
      "[1] Epoch has started!\n",
      "[1] Epoch has completed: loss=361.8883148918321 min_loss=7.620827091159299e-05 avg_ret=-200.0\n",
      "[2] Epoch has started!\n",
      "[2] Epoch has completed: loss=228.12890471004903 min_loss=1.8410824850434437e-05 avg_ret=-200.0\n",
      "[3] Epoch has started!\n",
      "[3] Epoch has completed: loss=166.91742463772334 min_loss=6.124999345047399e-06 avg_ret=-200.0\n",
      "[4] Epoch has started!\n",
      "[4] Epoch has completed: loss=125.67890689285832 min_loss=5.30208126292564e-06 avg_ret=-200.0\n",
      "[5] Epoch has started!\n",
      "[5] Epoch has completed: loss=100.46328944095694 min_loss=7.498708328057546e-06 avg_ret=-200.0\n",
      "[6] Epoch has started!\n",
      "[6] Epoch has completed: loss=84.08605581662368 min_loss=6.5629806158540305e-06 avg_ret=-200.0\n",
      "[7] Epoch has started!\n",
      "[7] Epoch has completed: loss=72.23479927427434 min_loss=5.189955118112266e-06 avg_ret=-200.0\n",
      "[8] Epoch has started!\n",
      "[8] Epoch has completed: loss=62.86966039840945 min_loss=6.020121873007156e-06 avg_ret=-200.0\n",
      "[9] Epoch has started!\n",
      "[9] Epoch has completed: loss=55.682454290875285 min_loss=5.5993568821577355e-06 avg_ret=-199.92\n",
      "Complete!\n",
      "CPU times: user 8min 51s, sys: 9min 49s, total: 18min 40s\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'[{epoch}] Epoch has started!')\n",
    "    for episode in range(EPISODES_PER_EPOCH):\n",
    "#         if episode % (EPISODES_PER_EPOCH / 5) == 0:\n",
    "#             print([f'[{epoch}] e{episode} has started!'])\n",
    "        obs = torch.as_tensor(env.reset(), dtype=torch.float32)\n",
    "        ep_ret = 0\n",
    "        ep_len = 0\n",
    "        ep_loss = 0\n",
    "        for t in count():\n",
    "            act = select_action(obs)\n",
    "            \n",
    "            next_obs, rew, done, _ = env.step(act)\n",
    "            done = False if ep_len == MAX_LEN else done\n",
    "            next_obs = torch.as_tensor(next_obs, dtype=torch.float32)\n",
    "                \n",
    "            ep_ret += rew\n",
    "            ep_len += 1\n",
    "            total_steps += 1\n",
    "            \n",
    "            if episode % (EPISODES_PER_EPOCH // 5) == 0:\n",
    "                env.render()\n",
    "            \n",
    "            buffer.put(obs, act, rew, next_obs, done)         \n",
    "            obs = next_obs\n",
    "            \n",
    "            optimize()\n",
    "            if done or ep_len == MAX_LEN:\n",
    "                break\n",
    "        Logger['ret'].append(ep_ret)\n",
    "        if episode % TARGET_UPDATE == 0 and episode > TARGET_UPDATE_AFTER:\n",
    "            ddqn.target.load_state_dict(ddqn.policy.state_dict())\n",
    "    epoch_loss = sum(Logger['loss'][start:])\n",
    "    epoch_min_loss = min(Logger['loss'][start:])\n",
    "    epoch_avg_ret = sum(Logger['ret'][epoch*EPISODES_PER_EPOCH:]) / (len(Logger['ret']) - epoch*EPISODES_PER_EPOCH)\n",
    "    print(f'[{epoch}] Epoch has completed: loss={epoch_loss} min_loss={epoch_min_loss} avg_ret={epoch_avg_ret}')\n",
    "    start = len(Logger['loss'])\n",
    "print('Complete!')\n",
    "env.render()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('jbr': conda)",
   "language": "python",
   "name": "python37764bitjbrcondafc333f67bcd147e89e693bf7996d3af5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
